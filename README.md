# Отработка навыков работы с Airflow. Разработка систем анализа больших данных ДЗ 2

## Краткое описание

В данном репозитории содержится проект, предназначенный для обучения и практики работы с Apache Airflow. 
Основная задача проекта — создать DAG, который будет запускать расчёт витрины активности клиентов, учитывая сумму и количество их транзакций.
Расчёты выполняются по расписанию, настроенному в Airflow.

## Содержание репозитория

- dags/ — папка с DAG-файлами.
- data/ — папка для хранения данных, необходимых для работы DAG.
- .env — файл с переменными окружения.
- .gitignore — файл с правилами исключений для Git.
- Dockerfile — инструкция для создания Docker-образа.
- README.md — документация проекта (вы читаете её).
- docker-compose.yaml — файл для запуска проекта в Docker.
- requirements.txt — список зависимостей Python.

## Установка и запуск

### Требования

- Docker
- Docker Compose
- Python

### Шаги установки

- Склонируйте репозиторий:

```
git clone https://github.com/Kaktys36/big_data_systems_hw_2.git
```
- Перейдите в директорию проекта:

```
cd big_data_systems_hw_2
```
- Соберите и запустите проект с помощью Docker Compose:

```
docker-compose up --build
```

- После запуска Docker Compose интерфейс Airflow будет доступен по адресу: http://localhost:8080. Войдите с указанными данными и проверьте, что ваш DAG отображается в списке.

### DAG: Описание процесса

DAG включает следующие шаги:

- Загрузка данных о транзакциях.
- Расчёт суммы и количества транзакций для каждого клиента.
- Загрузка результата в витрину данных.

### Зависимости

- Все зависимости перечислены в файле requirements.txt. Они будут установлены автоматически при сборке Docker-образа.
